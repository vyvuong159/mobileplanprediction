{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "- Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "- You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since youâ€™ve already performed the data preprocessing step, you can move straight to creating the model.\n",
    "- Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Open the data file and study the general information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open data file and study the general info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan = pd.read_csv('https://code.s3.yandex.net/datasets/users_behavior.csv')\n",
    "plan.info()\n",
    "plan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions for Step 1\n",
    "- There are 3214 observations, describing the info for each customer of Megaline.\n",
    "- The features include: calls (number of calls), minutes (total call duration in minutes), messages (number of text messages), mb_used (Internet traffic used in MB).\n",
    "- The target is the is_ultra variable: plan for the current month (Ultra - 1, Smart - 0).\n",
    "- There are no missing values (all variables have 3214 non-null observations).\n",
    "- The data types are correct for all variables.\n",
    "### Therefore we don't need to preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split the source data into a training set, a validation set, and a test set with the ratio 3:1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the feature and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = plan.drop('is_ultra', axis=1)\n",
    "target = plan['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the source data into a training set, a validation set, and a test set with the ratio 3:1:!\n",
    "Use train_split_test twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First split the data into 2 sets: 60% for train and 40% for test (actually for test and validate)\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(feature, target, \n",
    "                                                                           test_size=0.4, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second split the above data into further 2 sets of test and validate, each has 50% of data\n",
    "feature_val, feature_test, target_val, target_test = train_test_split(feature_test, target_test,\n",
    "                                                                     test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if each dataset has the correct proportion (60%, 20%, 20% of the total number of observations of the source data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.2\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "for data in [target_train, target_val, target_test]:\n",
    "    print(round(len(data)/len(target), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to split the data into 3 parts with the ratio 3:1:1, but not use in this project\n",
    "train, validate, test = np.split(plan.sample(frac=1), [int(.6*len(plan)), int(.8*len(plan))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Investigate the quality of different models by changing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type of models that are appropriate with our research goal:\n",
    "Because we want to predict a categorical variable (if a customer choose the **ultra plan** or not), we need to use **Classification** models, including:\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DecisionTreeClassfier model\n",
    "- Create a loop to test different hyperparameters (max_depth): test from 1-5\n",
    "- Then choose the best model based on accuracy score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth: 1\n",
      "Training set: 0.7655601659751037\n",
      "Validate set: 0.7387247278382582\n",
      "max_depth: 2\n",
      "Training set: 0.799792531120332\n",
      "Validate set: 0.7651632970451011\n",
      "max_depth: 3\n",
      "Training set: 0.8153526970954357\n",
      "Validate set: 0.7636080870917574\n",
      "max_depth: 4\n",
      "Training set: 0.8257261410788381\n",
      "Validate set: 0.7682737169517885\n",
      "max_depth: 5\n",
      "Training set: 0.8309128630705395\n",
      "Validate set: 0.7651632970451011\n",
      "max_depth: 6\n",
      "Training set: 0.8454356846473029\n",
      "Validate set: 0.7698289269051322\n",
      "max_depth: 7\n",
      "Training set: 0.8630705394190872\n",
      "Validate set: 0.7682737169517885\n",
      "max_depth: 8\n",
      "Training set: 0.870850622406639\n",
      "Validate set: 0.7682737169517885\n",
      "max_depth: 9\n",
      "Training set: 0.8807053941908713\n",
      "Validate set: 0.7744945567651633\n",
      "max_depth: 10\n",
      "Training set: 0.8921161825726142\n",
      "Validate set: 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1,11):\n",
    "    model1 = DecisionTreeClassifier(random_state=12, max_depth=depth)\n",
    "    model1.fit(feature_train, target_train)\n",
    "    print('max_depth:', depth)\n",
    "    print('Training set:', model1.score(feature_train, target_train))\n",
    "    print('Validate set:', model1.score(feature_val, target_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree model selection: Select the model with max_depth = 4 because its validation set's accuracy score is on the higher end, and the difference between training and test set is not too big (not too overfitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RandomForestClassfier model\n",
    "- Create a loop to test different hyperparameters (n_estimators): test from 10 - 100, take only factors of 10 (10, 20, 30, 40, 50, ..., 100), set the maximum_depth = 10\n",
    "- Then choose the best model based on accuracy score of the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 10\n",
      "Training set: 0.8941908713692946\n",
      "Validate set: 0.7807153965785381\n",
      "n_estimators: 20\n",
      "Training set: 0.8962655601659751\n",
      "Validate set: 0.7978227060653188\n",
      "n_estimators: 30\n",
      "Training set: 0.8978215767634855\n",
      "Validate set: 0.7962674961119751\n",
      "n_estimators: 40\n",
      "Training set: 0.8983402489626556\n",
      "Validate set: 0.7900466562986003\n",
      "n_estimators: 50\n",
      "Training set: 0.9004149377593361\n",
      "Validate set: 0.7931570762052877\n",
      "n_estimators: 60\n",
      "Training set: 0.8993775933609959\n",
      "Validate set: 0.7900466562986003\n",
      "n_estimators: 70\n",
      "Training set: 0.8978215767634855\n",
      "Validate set: 0.7916018662519441\n",
      "n_estimators: 80\n",
      "Training set: 0.8978215767634855\n",
      "Validate set: 0.7900466562986003\n",
      "n_estimators: 90\n",
      "Training set: 0.8967842323651453\n",
      "Validate set: 0.7900466562986003\n",
      "n_estimators: 100\n",
      "Training set: 0.8973029045643154\n",
      "Validate set: 0.7900466562986003\n"
     ]
    }
   ],
   "source": [
    "for estimator in range(10, 101, 10):\n",
    "    model2 = RandomForestClassifier(random_state=12, max_depth=10,\n",
    "                                    n_estimators=estimator)\n",
    "    model2.fit(feature_train, target_train)\n",
    "    print('n_estimators:', estimator)\n",
    "    print('Training set:', model2.score(feature_train, target_train))\n",
    "    print('Validate set:', model2.score(feature_val, target_val))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest model selection: Select the model with n_estimators = 20 because its validation set's accuracy score is highest, the run speed is also faster than the models with bigger n_estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LogisticRegression model\n",
    "No need to tune the hyperameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LogisticRegression(random_state=12, solver = 'liblinear')\n",
    "model3.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "Training set:  0.716804979253112\n",
      "Test set:  0.6780715396578538\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy')\n",
    "print('Training set: ', model3.score(feature_train, target_train))\n",
    "print('Test set: ', model3.score(feature_val, target_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Check the quality of the model using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the three models by comparing the accuracy score of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the selected model with their corresponding hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = DecisionTreeClassifier(random_state=12, max_depth=4)\n",
    "model2 = RandomForestClassifier(random_state=12, max_depth=10, n_estimators=20)\n",
    "model3 = LogisticRegression(random_state=12, solver = 'liblinear')                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the 3 models into our training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(feature_train, target_train)\n",
    "model2.fit(feature_train, target_train)\n",
    "model3.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions using 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_decisiontree = model1.predict(feature_test)\n",
    "\n",
    "prediction_test_randomforest = model2.predict(feature_test)\n",
    "\n",
    "prediction_test_logisticregression = model3.predict(feature_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Accuracy score using test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model : 0.7682737169517885\n",
      "Random Forest Model : 0.7822706065318819\n",
      "Logistic Regression Model : 0.6594090202177294\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Model\", \": \", end=\"\")\n",
    "print(accuracy_score(target_test, prediction_test_decisiontree))\n",
    "print(\"Random Forest Model\", \": \", end=\"\")\n",
    "print(accuracy_score(target_test, prediction_test_randomforest))\n",
    "print(\"Logistic Regression Model\", \": \", end=\"\")\n",
    "print(accuracy_score(target_test, prediction_test_logisticregression))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check overfitness by comparing the accuracy score between train and test sets for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model\n",
      "Training set: 0.8257261410788381\n",
      "Validate set: 0.7682737169517885\n",
      "Random Forest Model\n",
      "Training set: 0.8962655601659751\n",
      "Validate set: 0.7822706065318819\n",
      "Logistic Regression Model\n",
      "Training set: 0.716804979253112\n",
      "Validate set: 0.6594090202177294\n"
     ]
    }
   ],
   "source": [
    "print('Decision Tree Model')\n",
    "print('Training set:', model1.score(feature_train, target_train))\n",
    "print('Validate set:', model1.score(feature_test, target_test))\n",
    "      \n",
    "print('Random Forest Model')\n",
    "print('Training set:', model2.score(feature_train, target_train))\n",
    "print('Validate set:', model2.score(feature_test, target_test))    \n",
    "      \n",
    "print('Logistic Regression Model')\n",
    "print('Training set:', model3.score(feature_train, target_train))\n",
    "print('Validate set:', model3.score(feature_test, target_test))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model: Random Forest Model\n",
    "- Pro: It's accuracy score is the highest, also satisfying the threshold for accuracy score\n",
    "- Con: This model is also the most overfitted model. However, its accuracy might compensate for this overfitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Because we want to predict a categorical variable (if a customer choose the **ultra plan** or not), we need to use **Classification** models, including: Decision Tree Classifier, Random Forest Classifier, and Logistic Regression\n",
    "- The source data has been splitted into 3 sets: train, validation and test, where:\n",
    "    - Train set: used to train the models\n",
    "    - Validation set: used to tune hyperparameters for each model\n",
    "    - Test set: used to check the quality of the models\n",
    "- Factors involving in model selection:\n",
    "    - Accuracy score\n",
    "    - Run speed\n",
    "    - The trade-off between accuracy and overfitting/underfitting \n",
    "- After considering the above factors, the Random Forest Model was chosen\n",
    "- Caveat: There are some bias in selecting hyperameters. For example: for Decision Tree, only choose to test from 1 - 10, for Random Forest: choose the max_depth = 10 rather than creating combination between max_depth and n_estimators --> Need a better model selection method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
